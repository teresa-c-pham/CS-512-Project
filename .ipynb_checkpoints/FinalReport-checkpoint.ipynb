{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b94c7f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76349601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdef04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "292bd3ab",
   "metadata": {},
   "source": [
    "## GRU RNN - Pranav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389700ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774f000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79331796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a967e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ed4a90d",
   "metadata": {},
   "source": [
    "## LSTM - Teresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02c1feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieRev = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "movieRev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776348a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equal amounts, so there is no need to normalize\n",
    "movieRev['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3f10c",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd23d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the review with the highest number of words\n",
    "def maxWords(reviewList):\n",
    "    words = 5000        # Arbitrary value for max words\n",
    "    for review in reviewList:\n",
    "        if (len(review.split()) > words):\n",
    "            words = len(review.split())\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ad534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "reviewList = movieRev['review'].tolist()\n",
    "words = maxWords(reviewList)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f18b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical values to numeric using factorize()\n",
    "sentiment_label = movieRev['sentiment'].factorize()\n",
    "print(sentiment_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ed3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = movieRev['review'].values\n",
    "\n",
    "# Tokenize the words in text and fit to associate the words and labels\n",
    "tokenizer = Tokenizer(num_words=words)\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "# Identify the size of vocabulary\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Replace words with their assigned numbers using text_to_sequence()\n",
    "encoding = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "# Add padding so sentences can have equal length\n",
    "pad_sequence = pad_sequences(encoding, maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03bcd59",
   "metadata": {},
   "source": [
    "### LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df2a3e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 200, 32)           3976096   \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 200, 32)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               82432     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,058,657\n",
      "Trainable params: 4,058,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(128, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a3eab",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4dace",
   "metadata": {},
   "source": [
    "**[CAUTION]** May take over 10 minutes to run. <br>\n",
    "Base Model: 5 epochs, batch_size=32, validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b0444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 638/1250 [==============>...............] - ETA: 2:39 - loss: 0.4943 - accuracy: 0.7520"
     ]
    }
   ],
   "source": [
    "# Train for 5 epochs with batch size 32 and validation split 20%\n",
    "history = model.fit(pad_sequence,sentiment_label[0],validation_split=0.2, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df840258",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55728b",
   "metadata": {},
   "source": [
    "### Predict using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    tw = tokenizer.texts_to_sequences([text])\n",
    "    tw = pad_sequences(tw,maxlen=200)\n",
    "    prediction = int(model.predict(tw).round().item())\n",
    "#     print(\"Predicted label: \", sentiment_label[1][prediction])\n",
    "    return sentiment_label[1][prediction]\n",
    "\n",
    "test_sentence1 = \"I enjoyed this movie. The actors were very inspirational.\"\n",
    "print(predict_sentiment(test_sentence1))\n",
    "\n",
    "test_sentence2 = \"This is the worst movie I've ever seen in my life!\"\n",
    "print(predict_sentiment(test_sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b662fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Positive and Negative Testing Examples\n",
    "print(\"Number of Positive Examples:\", len(os.listdir(\"aclImdb/test/pos/\")))\n",
    "print(\"Number of Negative Examples:\", len(os.listdir(\"aclImdb/test/neg/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29b056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92fafcc8",
   "metadata": {},
   "source": [
    "## Transformer-based Model - Tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e994cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ff224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
