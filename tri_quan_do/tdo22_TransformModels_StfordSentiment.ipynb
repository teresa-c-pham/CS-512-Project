{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh9nKdk-cQJo"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4WmEy21dQir"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertForSequenceClassification, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sh90SGLQdUhw"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', num_labels=1\n",
        "    )\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V1AX7fC8dYau"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "with open('original_rt_snippets.txt', 'r') as f:\n",
        "    data_texts = f.readlines()\n",
        "\n",
        "with open('sentiment_labels.txt', 'r') as f:\n",
        "    data_label = f.readlines()\n",
        "\n",
        "data_texts = data_texts[0:100]\n",
        "data_label = data_label[1:101]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CmQt41wyfsf0"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "sentences = []\n",
        "\n",
        "for i in range(len(data_texts)):\n",
        "  label_id, label_val = data_label[i].split('|')\n",
        "  labels.append(float(label_val[:-1]))\n",
        "  sentences.append(data_texts[i][:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0XodnJDyZCP6"
      },
      "outputs": [],
      "source": [
        "# Tokenize input sentences\n",
        "encoded_inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to tensor\n",
        "labels_tensor = torch.FloatTensor(labels).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_str(my_string, value3):\n",
        "    for item in my_string:\n",
        "      if item not in values3:\n",
        "        my_string = my_string.replace(item, \"\")\n",
        "    return my_string"
      ],
      "metadata": {
        "id": "09NP1k8h-3JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Methodology to assign label when no label given\n",
        "# The map Reduce will base on the sentiment to assign\n",
        "# an appropriate score the a sentence\n",
        "def map_reduce(dataFrame):\n",
        "  if len(dataFrame) == 0:\n",
        "    return None\n",
        "  \n",
        "  sentimentString = dataFrame.astype(str)\n",
        "  tDesc = sentimentString['description']        # has all the original tweets\n",
        "\n",
        "  values3 = list(\"abcdefghijklmnopqrstuvwxyz\")  # Original list of alphabet\n",
        "\n",
        "  sentimentString = dataFrame.astype(str)\n",
        "  desWords = sentimentString['description'].apply(str.lower).str.split()\n",
        "\n",
        "  n = 0;  #assigns a unique n value to each sentence\n",
        "\n",
        "  reviewSentiment = {} # used to save n as key and score as value\n",
        "  descLen = {}         # saves n as key and score/length as value\n",
        "\n",
        "  for string in desWords:\n",
        "    length = 0\n",
        "    reviewSentiment[n] = 0\n",
        "    for word in string:\n",
        "      length += 1\n",
        "      word = remover_str(word, value3)\n",
        "      if word in positive:\n",
        "        reviewSentiment[n] += 1\n",
        "      if word in negative:\n",
        "        reviewSentiment[n] -= 1\n",
        "\n",
        "    if reviewSentiment[n] != 0:\n",
        "      descLen[n] = reviewSentiment[n]/length\n",
        "    n += 1\n",
        "\n",
        "  return reviewSentiment, descLen, n"
      ],
      "metadata": {
        "id": "DFDY5Sip-hxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Kc5Yw1rgv4j"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(**encoded_inputs, labels=labels_tensor)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch:', epoch, 'Training Loss:', loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NMcJsfmNg-cq"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**encoded_inputs)\n",
        "    predictions = outputs.logits.squeeze().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O-BXf7vrhAiC"
      },
      "outputs": [],
      "source": [
        "# Print some example predictions\n",
        "for i in range(10):\n",
        "    print(\"Sentence:\", sentences[i])\n",
        "    print(\"True score:\", labels[i])\n",
        "    print(\"Predicted score:\", predictions[i])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bWOUGVbwk301"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Prediction score graph visualization\n",
        "predict_score = predictions\n",
        "texting_label = range(0, len(predict_score))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(texting_label, predict_score, marker='')\n",
        "plt.xlabel('Text Label Contents ID')\n",
        "plt.ylabel('Text Label Scores w/ID')\n",
        "plt.title('Plot Prediction score graph visualization using Transformer-Based Model')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ky1vfvzrnM7A"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(texting_label, labels, marker='')\n",
        "plt.xlabel('Text Label Contents ID')\n",
        "plt.ylabel('Text Label True Scores')\n",
        "plt.title('Plot True Scores graph visualization using Transformer-Based Model')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AFpOIq2Nt9ZI"
      },
      "outputs": [],
      "source": [
        "text_string = \"Hello, I kinda love this movie and I may join that again in the future\"\n",
        "\n",
        "# Tokenize input string\n",
        "encoded_input = tokenizer(text_string, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Pass input string through the model to obtain predicted score\n",
        "with torch.no_grad():\n",
        "    outputs = model(**encoded_input)\n",
        "    predicted_score = outputs.logits.item()\n",
        "\n",
        "print(\"Predicted score for the input text is:\", predicted_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}